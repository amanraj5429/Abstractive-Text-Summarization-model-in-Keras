{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UikrhKKgal8U"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import re\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ5DnulHyR9v"
      },
      "source": [
        "**Loading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MYChsdSwUPm",
        "outputId": "5207a885-3d25-4815-8331-70188c822606",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "\n",
        "from google.colab import files \n",
        "  \n",
        "  \n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e5abc58f-af46-446b-ba33-00350a81e893\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e5abc58f-af46-446b-ba33-00350a81e893\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving news.xlsx to news.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LINNU9riwlNA"
      },
      "source": [
        "news = pd.read_excel(\"news.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2PFOk19xn74"
      },
      "source": [
        "news.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpkd80dSxzEe",
        "outputId": "3364baa8-a9d5-4868-e091-ef9b7fb66756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "news.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Short</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
              "      <td>The CBI on Saturday booked four former officia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
              "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
              "      <td>At least three people were killed, including a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why has Reliance been barred from trading in f...</td>\n",
              "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Was stopped from entering my own studio at Tim...</td>\n",
              "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline                                              Short\n",
              "0  4 ex-bank officials booked for cheating bank o...  The CBI on Saturday booked four former officia...\n",
              "1     Supreme Court to go paperless in 6 months: CJI  Chief Justice JS Khehar has said the Supreme C...\n",
              "2  At least 3 killed, 30 injured in blast in Sylh...  At least three people were killed, including a...\n",
              "3  Why has Reliance been barred from trading in f...  Mukesh Ambani-led Reliance Industries (RIL) wa...\n",
              "4  Was stopped from entering my own studio at Tim...  TV news anchor Arnab Goswami has said he was t..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCUhWSbgx4bu",
        "outputId": "17dead43-cf72-4de8-bcd4-c9a9ff192343",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "news.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55104, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwSkA1Yqx-nb"
      },
      "source": [
        "document = news['Short']\n",
        "summary = news['Headline']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwteZr0kyFP0",
        "outputId": "f47389ca-a8e7-4206-f89b-58ed2866108f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "document[30], summary[30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('According to the Guinness World Records, the most generations alive in a single family have been seven.  The difference between the oldest and the youngest person in the family was about 109 years, when Augusta Bunge&#39;s great-great-great-great grandson was born on January 21, 1989. The family belonged to the United States of America.',\n",
              " 'The most generations alive in a single family have been 7')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUHpv5yizYNK"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeQfKgGsyN09",
        "outputId": "9b4a13ed-369c-433e-e491-f8eaabd103d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# for decoder sequence\n",
        "summary = summary.apply(lambda x: '<go> ' + x + ' <stop>')\n",
        "summary.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    <go> 4 ex-bank officials booked for cheating b...\n",
              "1    <go> Supreme Court to go paperless in 6 months...\n",
              "2    <go> At least 3 killed, 30 injured in blast in...\n",
              "3    <go> Why has Reliance been barred from trading...\n",
              "4    <go> Was stopped from entering my own studio a...\n",
              "Name: Headline, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwmFdLRQ0GfJ"
      },
      "source": [
        "**Tokenizing the texts into integer tokens**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYMFOn8azfrm"
      },
      "source": [
        "# since < and > from default tokens cannot be removed\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhM_H1G01xjc"
      },
      "source": [
        "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC6GDKXt11st"
      },
      "source": [
        "document_tokenizer.fit_on_texts(document)\n",
        "summary_tokenizer.fit_on_texts(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqOulsUG18_U"
      },
      "source": [
        "inputs = document_tokenizer.texts_to_sequences(document)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2Vv9Lqp2CoF",
        "outputId": "b2b1b759-1474-4160-dcc7-369899da3b27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "summary_tokenizer.texts_to_sequences([\"This is a test\"])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[184, 22, 12, 71]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lFYsh1Z2Mxv",
        "outputId": "b5fa47c4-96f9-4441-ec27-0884e789e079",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "summary_tokenizer.sequences_to_texts([[184, 22, 12, 71]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this is a test']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw1iB8Oy2RIb",
        "outputId": "56a722c7-cf44-40ec-fd0b-6ac537105474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "# vocab_size\n",
        "encoder_vocab_size, decoder_vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76362, 29661)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I6fgYPK2bla"
      },
      "source": [
        "**Obtaining insights on lengths for defining maxlen**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufsNkSKG2f_F"
      },
      "source": [
        "document_lengths = pd.Series([len(x) for x in document])\n",
        "summary_lengths = pd.Series([len(x) for x in summary])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FxopL7l2nmV",
        "outputId": "53eacca9-5ffd-4707-b8d6-dc7a796e129b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "document_lengths.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean       368.003049\n",
              "std         26.235510\n",
              "min        280.000000\n",
              "25%        350.000000\n",
              "50%        369.000000\n",
              "75%        387.000000\n",
              "max        469.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysCZbK7I2sF0",
        "outputId": "4340dd88-02d2-4edc-972d-43a5a8b0ff8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "summary_lengths.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean        63.620282\n",
              "std          7.267463\n",
              "min         20.000000\n",
              "25%         59.000000\n",
              "50%         63.000000\n",
              "75%         69.000000\n",
              "max         96.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ1moYK_2xKr"
      },
      "source": [
        "# maxlen\n",
        "# taking values > and round figured to 75th percentile\n",
        "# at the same time not leaving high variance\n",
        "encoder_maxlen = 400\n",
        "decoder_maxlen = 75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQgBr5Ww25JT"
      },
      "source": [
        "**Padding/Truncating sequences for identical sequence lengths**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmbPVhAI21od"
      },
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqAfq6nV3DUj"
      },
      "source": [
        "**Creating dataset pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKQKsbIc3GI9"
      },
      "source": [
        "inputs = tf.cast(inputs, dtype=tf.int32)\n",
        "targets = tf.cast(targets, dtype=tf.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGpUDxz63-a_"
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAWsQv064F6e"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUEMaB2a4NYr"
      },
      "source": [
        "**Positional Encoding for adding notion of position among words as unlike RNN this is non-directional**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veD1BiJk4QNQ"
      },
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa8YSCSq4Y_q"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis],\n",
        "        np.arange(d_model)[np.newaxis, :],\n",
        "        d_model\n",
        "    )\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1Eu3WUt4gQ5"
      },
      "source": [
        "**Masking**\n",
        "\n",
        "*Padding mask for masking \"pad\" sequences.\n",
        "\n",
        "*Lookahead mask for masking future words from contributing in prediction of current words in self attention\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnk9--_z4a6J"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIC67Q2a5F6C"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c7F9HNx5M0K"
      },
      "source": [
        "**Building the Model**\n",
        "\n",
        "**Scaled Dot Product**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Kw_om05ZxZ"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws8_zQ_C5fw1"
      },
      "source": [
        "**Multi-Headed Attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M8l35wz5cCu"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "            \n",
        "        return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xx5e-QpBMPS"
      },
      "source": [
        "**Feed Forward Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKobfKm-BOUB"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKekZmNOBvut"
      },
      "source": [
        "**Fundamental Unit of Transformer encode**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSRELYQaBx9F"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbd6OVuICXLc"
      },
      "source": [
        "\n",
        "**Fundamental Unit of Transformer decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzB7-oYlB5_E"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_1kLxQDCmf4"
      },
      "source": [
        "**Encoder consisting of multiple EncoderLayer(s)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHvSx7hiCorL"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "    \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJelnLexC8F8"
      },
      "source": [
        "**Decoder consisting of multiple DecoderLayer(s)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBTENIIBC-D9"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "        return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piSm2t7ODN2R"
      },
      "source": [
        "**Finally, the Transformer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqTk8-f_DJ7n"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQCBBMvWDZMg"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZE_MOZxDov3"
      },
      "source": [
        "# hyper-params\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJQLisIaEDdn"
      },
      "source": [
        "**Adam optimizer with custom learning rate scheduling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLGKGTlcEGz8"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7tWvgpOEP-1"
      },
      "source": [
        "**Defining losses and other metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLLRS8niESIH"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nktX1v5sEa8q"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6H2FIVwEcCU"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtXzVqcCEgtV"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NKgXCSLE2v0"
      },
      "source": [
        "**Transformer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKVRfY0aE7nt"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers, \n",
        "    d_model, \n",
        "    num_heads, \n",
        "    dff,\n",
        "    encoder_vocab_size, \n",
        "    decoder_vocab_size, \n",
        "    pe_input=encoder_vocab_size, \n",
        "    pe_target=decoder_vocab_size,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBf1rTXTFEck"
      },
      "source": [
        "**Masks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfQ-PrGlFBLd"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYLyOU7QFN_i"
      },
      "source": [
        "**Checkpoints**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91Fu0KSqFK0K"
      },
      "source": [
        "checkpoint_path = \"checkpoints\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWAorYVaFXwr"
      },
      "source": [
        "**Training steps**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE30pne1FT-g"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp, \n",
        "            True, \n",
        "            enc_padding_mask, \n",
        "            combined_mask, \n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL8tHfVQFlrj",
        "outputId": "bf606952-5ee9-4c4b-9f58-16eac224f05b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "  \n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        train_step(inp, tar)\n",
        "    \n",
        "        # 55k samples\n",
        "        # we display 3 batch results -- 0th, middle and last one (approx)\n",
        "        # 55k / 64 ~ 858; 858 / 2 = 429\n",
        "        if batch % 429 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
        "      \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "    \n",
        "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
        "\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 10.3064\n",
            "Epoch 1 Batch 429 Loss 9.2000\n",
            "Epoch 1 Batch 858 Loss 8.2406\n",
            "Epoch 1 Loss 8.2376\n",
            "Time taken for 1 epoch: 419.9579463005066 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 7.0481\n",
            "Epoch 2 Batch 429 Loss 6.8197\n",
            "Epoch 2 Batch 858 Loss 6.6174\n",
            "Epoch 2 Loss 6.6161\n",
            "Time taken for 1 epoch: 414.93183636665344 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 6.1585\n",
            "Epoch 3 Batch 429 Loss 6.0891\n",
            "Epoch 3 Batch 858 Loss 5.9476\n",
            "Epoch 3 Loss 5.9473\n",
            "Time taken for 1 epoch: 413.69479727745056 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 5.6344\n",
            "Epoch 4 Batch 429 Loss 5.5694\n",
            "Epoch 4 Batch 858 Loss 5.4614\n",
            "Epoch 4 Loss 5.4608\n",
            "Time taken for 1 epoch: 412.4186272621155 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 5.2658\n",
            "Epoch 5 Batch 429 Loss 5.1493\n",
            "Epoch 5 Batch 858 Loss 5.0865\n",
            "Saving checkpoint for epoch 5 at checkpoints/ckpt-1\n",
            "Epoch 5 Loss 5.0863\n",
            "Time taken for 1 epoch: 412.5258455276489 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 5.0785\n",
            "Epoch 6 Batch 429 Loss 4.7725\n",
            "Epoch 6 Batch 858 Loss 4.6977\n",
            "Epoch 6 Loss 4.6976\n",
            "Time taken for 1 epoch: 410.132385969162 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 4.6395\n",
            "Epoch 7 Batch 429 Loss 4.3923\n",
            "Epoch 7 Batch 858 Loss 4.3507\n",
            "Epoch 7 Loss 4.3500\n",
            "Time taken for 1 epoch: 410.36021637916565 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 4.0644\n",
            "Epoch 8 Batch 429 Loss 4.1056\n",
            "Epoch 8 Batch 858 Loss 4.0698\n",
            "Epoch 8 Loss 4.0694\n",
            "Time taken for 1 epoch: 410.4758176803589 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 3.8152\n",
            "Epoch 9 Batch 429 Loss 3.8588\n",
            "Epoch 9 Batch 858 Loss 3.8449\n",
            "Epoch 9 Loss 3.8447\n",
            "Time taken for 1 epoch: 410.66005182266235 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 3.7127\n",
            "Epoch 10 Batch 429 Loss 3.6646\n",
            "Epoch 10 Batch 858 Loss 3.6727\n",
            "Saving checkpoint for epoch 10 at checkpoints/ckpt-2\n",
            "Epoch 10 Loss 3.6727\n",
            "Time taken for 1 epoch: 411.2657916545868 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 3.6397\n",
            "Epoch 11 Batch 429 Loss 3.5169\n",
            "Epoch 11 Batch 858 Loss 3.5229\n",
            "Epoch 11 Loss 3.5229\n",
            "Time taken for 1 epoch: 410.25653624534607 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 3.4046\n",
            "Epoch 12 Batch 429 Loss 3.3641\n",
            "Epoch 12 Batch 858 Loss 3.3799\n",
            "Epoch 12 Loss 3.3805\n",
            "Time taken for 1 epoch: 410.53344774246216 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 3.3314\n",
            "Epoch 13 Batch 429 Loss 3.2309\n",
            "Epoch 13 Batch 858 Loss 3.2434\n",
            "Epoch 13 Loss 3.2430\n",
            "Time taken for 1 epoch: 410.3993811607361 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 2.9949\n",
            "Epoch 14 Batch 429 Loss 3.0955\n",
            "Epoch 14 Batch 858 Loss 3.1194\n",
            "Epoch 14 Loss 3.1200\n",
            "Time taken for 1 epoch: 412.2958023548126 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 2.9183\n",
            "Epoch 15 Batch 429 Loss 2.9929\n",
            "Epoch 15 Batch 858 Loss 3.0091\n",
            "Saving checkpoint for epoch 15 at checkpoints/ckpt-3\n",
            "Epoch 15 Loss 3.0093\n",
            "Time taken for 1 epoch: 411.9049687385559 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 2.8107\n",
            "Epoch 16 Batch 429 Loss 2.8807\n",
            "Epoch 16 Batch 858 Loss 2.9045\n",
            "Epoch 16 Loss 2.9043\n",
            "Time taken for 1 epoch: 411.1157205104828 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 2.7702\n",
            "Epoch 17 Batch 429 Loss 2.7921\n",
            "Epoch 17 Batch 858 Loss 2.8159\n",
            "Epoch 17 Loss 2.8160\n",
            "Time taken for 1 epoch: 410.90769243240356 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 2.7381\n",
            "Epoch 18 Batch 429 Loss 2.7000\n",
            "Epoch 18 Batch 858 Loss 2.7283\n",
            "Epoch 18 Loss 2.7288\n",
            "Time taken for 1 epoch: 410.9676854610443 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 2.5528\n",
            "Epoch 19 Batch 429 Loss 2.6200\n",
            "Epoch 19 Batch 858 Loss 2.6492\n",
            "Epoch 19 Loss 2.6494\n",
            "Time taken for 1 epoch: 410.76802349090576 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 2.5740\n",
            "Epoch 20 Batch 429 Loss 2.5396\n",
            "Epoch 20 Batch 858 Loss 2.5758\n",
            "Saving checkpoint for epoch 20 at checkpoints/ckpt-4\n",
            "Epoch 20 Loss 2.5761\n",
            "Time taken for 1 epoch: 411.2475392818451 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvyc5IMl5eSD"
      },
      "source": [
        "**Inference**\n",
        "\n",
        "Predicting one word at a time at the decoder and appending it to the output; then taking the complete sequence as an input to the decoder and repeating until maxlen or stop keyword appears"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1JfEBbF5R6U"
      },
      "source": [
        "def evaluate(input_document):\n",
        "    input_document = document_tokenizer.texts_to_sequences([input_document])\n",
        "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
        "\n",
        "    decoder_input = [summary_tokenizer.word_index[\"<go>\"]]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(decoder_maxlen):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input, \n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == summary_tokenizer.word_index[\"<stop>\"]:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbSSR-T_5n6p"
      },
      "source": [
        "def summarize(input_document):\n",
        "    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
        "    summarized = evaluate(input_document=input_document)[0].numpy()\n",
        "    summarized = np.expand_dims(summarized[1:], 0)  # not printing <go> token\n",
        "    return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated document"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HM5JJj76C98",
        "outputId": "93bf6c52-19c9-4475-91a2-aa76d12929e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "summarize(\n",
        "    \"US-based private equity firm General Atlantic is in talks to invest about \\\n",
        "    $850 million to $950 million in Reliance Industries' digital unit Jio \\\n",
        "    Platforms, the Bloomberg reported. Saudi Arabia's $320 billion sovereign \\\n",
        "    wealth fund is reportedly also exploring a potential investment in the \\\n",
        "    Mukesh Ambani-led company. The 'Public Investment Fund' is looking to \\\n",
        "    acquire a minority stake in Jio Platforms.\"\n",
        ")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'verizon to invest 250 bn on yahoo deal with general motors'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atsQqaDZ6J7J",
        "outputId": "17a5149c-d8a4-4bfb-f66a-d876f29b2aea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "checkpoint_path = \"./checkpoints\"\n",
        "ckpt_path = tf.train.latest_checkpoint(checkpoint_path)\n",
        "ckpt.restore(ckpt_path)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f87bc169550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8NpERkg6-Ft",
        "outputId": "33683531-53df-4367-b00b-452cfca123d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "summarize(\n",
        "    \"Lebanese officials targeted in the investigation of the massive blast that tore through Beirut sought to shift blame for the presence of explosives at the citys port, and the visiting French president warned Thursday that without serious reforms \\\n",
        "    the country would continue to sink. The blast Tuesday, which appeared to have been caused by an accidental fire that ignited a warehouse full of ammonium nitrate at the citys port, rippled across the Lebanese capital, killing at least 135 people, \\\n",
        "    injuring more than 5,000 and causing widespread destruction. It also may have accelerated the countrys coronavirus outbreak, as thousands flooded into hospitals in the wake of the blast. Tens of thousands have been forced to move in with relatives \\\n",
        "    and friends after their homes were damaged, further raising the risks of exposure. French President Emmanuel Macron visited Thursday amid widespread pledges of international aid. Its unclear how much support the international community will offer \\\n",
        "    the notoriously corrupt and dysfunctional government. Macron, who viewed the devastated port and was to meet with senior Lebanese officials, said the visit is an opportunity to have a frank and challenging dialogue with the Lebanese political \\\n",
        "    powers and institutions., He said France will work to coordinate aid but warned that if reforms are not made, Lebanon will continue to sink., Later, as he toured one of the hardest-hit neighborhoods, an angry crowd vented its fury at Lebanons \\\n",
        "    political leaders, chanting Revolution and The people want to bring down the regime, slogans used during mass protests last year. Macron said he was not there to endorse the regime and vowed that French aid would not fall into the hands of \\\n",
        "    corruption.\"\n",
        ")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'congo probe ordered into 34 massacre 34 trial 34'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SzrrjZP8JPu",
        "outputId": "14696e98-5e58-4b52-c18d-5abc261fc600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "summarize(\n",
        "    \"Lebanese officials targeted in the investigation of the massive blast that tore through Beirut sought to shift blame for the presence of explosives at the citys port, and the visiting French president warned Thursday that without serious reforms \\\n",
        "    the country would continue to sink. The blast Tuesday, which appeared to have been caused by an accidental fire that ignited a warehouse full of ammonium nitrate at the citys port, rippled across the Lebanese capital, killing at least 135 people, \\\n",
        "    injuring more than 5,000 and causing widespread destruction.\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'congo fire kills suspected militants'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi5GwFgY8Qet",
        "outputId": "80a77d45-ea2c-4509-c55e-f1d041ac9bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "summarize(\n",
        "    \"French President Emmanuel Macron visited Thursday amid widespread pledges of international aid. It's unclear how much support the international community will offer the notoriously corrupt and dysfunctional government. \\\n",
        "    Macron, who viewed the devastated port and was to meet with senior Lebanese officials, said the visit is an opportunity to have a frank and challenging dialogue with the Lebanese political powers and institutions. He said France will work to coordinate aid but warned that if reforms are not made, Lebanon will continue to sink.\")\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dutch pm announces low death penalty to counter terrorism'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    }
  ]
}